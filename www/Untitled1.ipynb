{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26de9bf9-bb28-4a44-8fda-b7383f4c23c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lm/1s7yhzbn56l3gt6dp_gzhtgc0000gn/T/ipykernel_86217/4064121476.py:18: DeprecationWarning: the ``irsa_dust`` module has been moved to astroquery.ipac.irsa.irsa_dust, please update your imports.\n",
      "  from astroquery.irsa_dust import IrsaDust\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "'''\n",
    "Created on Wed Oct  7 12:14:39 2020\n",
    "\n",
    "@author: Alexander Crabtree\n",
    "            acrabtree15@gmail.com\n",
    "'''\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "import itertools\n",
    "import threading\n",
    "import time\n",
    "from astropy import units as u\n",
    "from astroquery.irsa_dust import IrsaDust\n",
    "from astropy.coordinates import Angle,SkyCoord\n",
    "from astropy.coordinates.name_resolve import NameResolveError\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def getLink(name):\n",
    "    '''\n",
    "    Grabs the link from this site for the Host name of supernovae in CSV,\n",
    "    returns the parsed page\n",
    "    '''\n",
    "    try:\n",
    "        link = \"http://ned.ipac.caltech.edu/cgi-bin/nph-objsearch?\"\n",
    "        inputs = {'objname': name,\n",
    "\t\t\t\t'extend': 'no',\n",
    "\t\t\t\t'hconst': '73.04',\n",
    "\t\t\t\t'omegam': '0.27',\n",
    "\t\t\t\t'omegav': '0.73',\n",
    "\t\t\t\t'corr_z': '1',\n",
    "\t\t\t\t'out_csys': 'Equatorial',\n",
    "\t\t\t\t'out_equinox': 'J2000.0',\n",
    "\t\t\t\t'obj_sort': \"RA or Longitude\",\n",
    "\t\t\t\t'of': 'pre_text',\n",
    "\t\t\t\t'zv_breaker': '30000.0',\n",
    "\t\t\t\t'list_limit':'10',\n",
    "\t\t\t\t'img_stamp': 'YES'}\n",
    "        page = requests.get(link, params = inputs)\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        return soup\n",
    "    except requests.ConnectionError:\n",
    "        soup = ''\n",
    "        return soup\n",
    "\n",
    "'''\n",
    "Takes parsed page from getlink and searches for all velocites listed below\n",
    "then returns the data.\n",
    "'''\n",
    "def scrapeValues(soup):\n",
    "\t\n",
    "    try:\n",
    "        soup = soup.find(\"a\", attrs={'name':'DerivedValues_0'})\n",
    "        velocities = soup.next_sibling.next_sibling.next_sibling.find(\"pre\")\n",
    "        Helio = list(velocities.children)[2]\n",
    "        VGS = list(velocities.children)[16]\n",
    "        Helio = Helio.lstrip('\\n')\n",
    "        VGS = VGS.lstrip('\\n')\n",
    "        Hvals = [int(s) for s in Helio.split() if s.isdigit()]\n",
    "        VGSVals = [int(s) for s in VGS.split() if s.isdigit()]\n",
    "        vels = [Hvals[0],Hvals[1],VGSVals[0],VGSVals[1]]\n",
    "        return vels\n",
    "    except: \n",
    "        vels = [np.nan,np.nan,np.nan,np.nan]\n",
    "        return vels\n",
    "\n",
    "def get_coords(gals):\n",
    "    \"\"\"\n",
    "    Takes list of galaxies and looks up their coordinates by name.\n",
    "    If no name found: warn, skip, remove galaxy from list\n",
    "\n",
    "    Returns:\n",
    "        gals: list of galaxies minus those that weren't found\n",
    "        start_coord: list of coordinates corresponding to center of galaxies in 'gals'\n",
    "    \"\"\"\n",
    "    start_coord = []\n",
    "    #bar = FillingCirclesBar('Loading galaxies', max = len(gals))\n",
    "    try:\n",
    "        tempCoord = SkyCoord.from_name(str(gals), frame = 'icrs')\n",
    "        start_coord= tempCoord\n",
    "            #bar.next()\n",
    "    except NameResolveError:\n",
    "        #if gals != str(''):\n",
    "            #print('\\nSkipping',gals,'because it couldn\\'t be found.')\n",
    "            #start_coord= ''\n",
    "        #else:\n",
    "            start_coord= np.nan\n",
    "    #bar.finish()\n",
    "    return(start_coord)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5266c942-99bc-4fe9-b492-27b9a33f17a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Dist_mod():\n",
    "    def Dist_mod_empty(hv, hv_err):\n",
    "        ''' \n",
    "        Returns empty nan series if condition is met\n",
    "        '''\n",
    "        distance_mod_cor, distance_mod_cor_err = np.nan, np.nan\n",
    "        return distance_mod_cor, distance_mod_cor_err\n",
    "    def Distance_mod_cor(hv, hv_err):\n",
    "        '''\n",
    "        Takes host_velocity and host_vel_err data and returns distance modulus\n",
    "        and distance modulus err in a series\n",
    "        '''\n",
    "        h0 = 73.04\n",
    "        h0err = 1.04\n",
    "\t# From Riess et al 2022 SH0ES result\n",
    "\n",
    "        try:\n",
    "            distance_mod_cor = 5*math.log(float(hv)/h0,10)+25 #hubble flow\n",
    "            distance_mod_cor_err = math.sqrt(((5*float(hv_err))/(float(hv)*math.log(10,10)))**2+((5*200)/(float(hv)*math.log(10,10)))**2 + ((5*5.0)/(h0*math.log(10,10)))**2)\n",
    "        except Exception:\n",
    "            distance_mod_cor, distance_mod_cor_err = np.nan, np.nan\n",
    "\n",
    "        return  distance_mod_cor, distance_mod_cor_err\n",
    "\n",
    "    dist= pd.Series(swift.apply(lambda row: Distance_mod_cor(row['host_velocity'], row['host_vel_err']) if pd.notna(row['host_velocity']) else Dist_mod_empty(row['host_velocity'], row['host_vel_err']), axis=1))\n",
    "    dist= pd.DataFrame(dist.tolist(), columns=['Hubble_dm', 'Hubble_dm_err'], index=dist.index)\n",
    "    dist= dist.replace({r'^\\s*$'}, np.nan, regex=True)\n",
    "    return dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9ccd15e-8d7d-4624-ba50-a2e0f4acf120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "import itertools\n",
    "import threading\n",
    "import time\n",
    "from astropy import units as u\n",
    "from astroquery.irsa_dust import IrsaDust\n",
    "from astropy.coordinates import Angle,SkyCoord\n",
    "from astropy.coordinates.name_resolve import NameResolveError\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def getLink(name):\n",
    "    '''\n",
    "    Grabs the link from this site for the Host name of supernovae in CSV,\n",
    "    returns the parsed page\n",
    "    '''\n",
    "    try:\n",
    "        link = \"http://ned.ipac.caltech.edu/cgi-bin/nph-objsearch?\"\n",
    "        inputs = {'objname': name,\n",
    "\t\t\t\t'extend': 'no',\n",
    "\t\t\t\t'hconst': '73.04',\n",
    "\t\t\t\t'omegam': '0.27',\n",
    "\t\t\t\t'omegav': '0.73',\n",
    "\t\t\t\t'corr_z': '1',\n",
    "\t\t\t\t'out_csys': 'Equatorial',\n",
    "\t\t\t\t'out_equinox': 'J2000.0',\n",
    "\t\t\t\t'obj_sort': \"RA or Longitude\",\n",
    "\t\t\t\t'of': 'pre_text',\n",
    "\t\t\t\t'zv_breaker': '30000.0',\n",
    "\t\t\t\t'list_limit':'10',\n",
    "\t\t\t\t'img_stamp': 'YES'}\n",
    "        page = requests.get(link, params = inputs)\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        return soup\n",
    "    except requests.ConnectionError:\n",
    "        soup = ''\n",
    "        return soup\n",
    "\n",
    "'''\n",
    "Takes parsed page from getlink and searches for all velocites listed below\n",
    "then returns the data.\n",
    "'''\n",
    "def scrapeValues(soup):\n",
    "\t\n",
    "    try:\n",
    "        soup = soup.find(\"a\", attrs={'name':'DerivedValues_0'})\n",
    "        velocities = soup.next_sibling.next_sibling.next_sibling.find(\"pre\")\n",
    "        Helio = list(velocities.children)[2]\n",
    "        VGS = list(velocities.children)[16]\n",
    "        Helio = Helio.lstrip('\\n')\n",
    "        VGS = VGS.lstrip('\\n')\n",
    "        Hvals = [int(s) for s in Helio.split() if s.isdigit()]\n",
    "        VGSVals = [int(s) for s in VGS.split() if s.isdigit()]\n",
    "        vels = [Hvals[0],Hvals[1],VGSVals[0],VGSVals[1]]\n",
    "        return vels\n",
    "    except: \n",
    "        vels = [np.nan,np.nan,np.nan,np.nan]\n",
    "        return vels\n",
    "\n",
    "def get_coords(gals):\n",
    "    \"\"\"\n",
    "    Takes list of galaxies and looks up their coordinates by name.\n",
    "    If no name found: warn, skip, remove galaxy from list\n",
    "\n",
    "    Returns:\n",
    "        gals: list of galaxies minus those that weren't found\n",
    "        start_coord: list of coordinates corresponding to center of galaxies in 'gals'\n",
    "    \"\"\"\n",
    "    start_coord = []\n",
    "    #bar = FillingCirclesBar('Loading galaxies', max = len(gals))\n",
    "    try:\n",
    "        tempCoord = SkyCoord.from_name(str(gals), frame = 'icrs')\n",
    "        start_coord= tempCoord\n",
    "            #bar.next()\n",
    "    except NameResolveError:\n",
    "        #if gals != str(''):\n",
    "            #print('\\nSkipping',gals,'because it couldn\\'t be found.')\n",
    "            #start_coord= ''\n",
    "        #else:\n",
    "            start_coord= np.nan\n",
    "    #bar.finish()\n",
    "    return(start_coord)\n",
    "\n",
    "def coord_breakup(coord):\n",
    "    \"\"\"\n",
    "    Breaks up a coordinate into its components\n",
    "    \"\"\"\n",
    "    if pd.isna(coord) == True:\n",
    "        ra = np.nan\n",
    "        dec = np.nan\n",
    "        return ra, dec\n",
    "    else:\n",
    "        ra = Angle(coord.ra.hour,unit = u.hour)\n",
    "        dec = coord.dec\n",
    "        return ra, dec\n",
    "\n",
    "\n",
    "def Redshift(soup):\n",
    "    '''\n",
    "    Takes parsed page from getlink and searches for redshift then returns that data\n",
    "    '''\n",
    "    try:\n",
    "        soup = soup.find(\"a\", attrs={'name':'BasicData_0'})\n",
    "        soup = soup.next_sibling.next_sibling.next_sibling.find(\"pre\")\n",
    "        redshift = list(soup.children)[0]\n",
    "        # print(redshift)\n",
    "        redshift = str(redshift).split(\"Redshift\",1)[1]\n",
    "        # print(redshift)\n",
    "        redshift = redshift.split(\":\",1)[1]\n",
    "        redshift = redshift.split(\" +\",1)[0].strip(' ')\n",
    "        return(redshift)\n",
    "    except:\n",
    "        redshift = np.nan\n",
    "        return redshift\n",
    "   \n",
    "\n",
    "def Morphology(soup):\n",
    "    '''\n",
    "    Takes parsed page from getlink and searches for morphology then returns the data\n",
    "    '''\n",
    "    try:\n",
    "        soup = soup.find(\"a\", attrs={'name':'BasicData_0'})\n",
    "        morphology = soup.next_sibling.next_sibling.next_sibling.find(\"pre\")\n",
    "        morphology = list(morphology.children)[2]\n",
    "        morphology = (morphology.split(\": \",4)[4]).rstrip()\n",
    "        return morphology\n",
    "    except:\n",
    "        morphology = np.nan\n",
    "        return morphology\n",
    "\n",
    "\n",
    "def LatLong(soup):\n",
    "    '''\n",
    "    Takes parsed page from getlink and searches for Latitude and Longitude then returns the data\n",
    "    '''\n",
    "    try:\n",
    "        soup = soup.find(\"a\", attrs={'name':'Positions_0'})\n",
    "        coords = soup.next_sibling.next_sibling.find(\"pre\")\n",
    "        coords = list(coords.children)[4]\n",
    "        coords = (coords.split(\"Galactic \",1)[1]).lstrip()\n",
    "        long, lat = str(coords.split()[0]), str(coords.split()[1])\n",
    " \n",
    "        return long, lat\n",
    "    except:\n",
    "        long, lat= np.nan,np.nan\n",
    "        return long, lat  \n",
    " \n",
    "\n",
    "def SN_host_ra_dec():\n",
    "    def jprint(obj):\n",
    "        '''\n",
    "        Used to interpret the data from astrocats catalog\n",
    "        '''\n",
    "        text = json.dumps(obj, sort_keys=True, indent=4)\n",
    "        print(text)\n",
    "\n",
    "    '''\n",
    "    Requests data ra, dec, and host data of all supernovae in astrocats catalog\n",
    "    '''\n",
    "    sn_data= requests.get(\"https://api.astrocats.space/catalog/ra+dec+host?first\")\n",
    "    sn_catalog= sn_data.json()\n",
    "\n",
    "    def SNHost(SNname):\n",
    "        ''' \n",
    "        Checks if any CSV Supernova names are in astrocats catalog\n",
    "        If yes returns Host Name data, If no returns nan value\n",
    "        '''\n",
    "        \n",
    "        if SNname in sn_catalog:\n",
    "            try:\n",
    "                host_names= sn_catalog[SNname]['host']['value']\n",
    "            except Exception:\n",
    "                host_names= np.nan\n",
    "        else:\n",
    "            host_names= np.nan\n",
    "\n",
    "        return host_names\n",
    "\n",
    "    def SNRa(SNname):\n",
    "        ''' \n",
    "        Checks if any CSV Supernova names are in astrocats catalog\n",
    "        If yes returns Ra data, If no returns nan value\n",
    "        '''\n",
    "        \n",
    "        if SNname in sn_catalog:\n",
    "            try:\n",
    "                snra= \"'%s\" % sn_catalog[SNname]['ra']['value']\n",
    "            except Exception: \n",
    "                snra= np.nan\n",
    "        else:\n",
    "            snra= np.nan\n",
    "        return snra\n",
    "\n",
    "    def SNDec(SNname):\n",
    "        ''' \n",
    "        Checks if any CSV Supernova names are in astrocats catalog\n",
    "        If yes returns Dec data, If no returns nan value\n",
    "        '''\n",
    "        \n",
    "        if SNname in sn_catalog:\n",
    "            try:\n",
    "                sndec= sn_catalog[SNname]['dec']['value']\n",
    "            except Exception: #if no dec value input what is given for dec \n",
    "                sndec= np.nan\n",
    "        else:\n",
    "            sndec= np.nan\n",
    "        return sndec\n",
    "        \n",
    "    '''\n",
    "    The next 3 lines uses pandas apply function and lambda function to quickly\n",
    "    parse supernovae names into the 3 above functions and saves data to\n",
    "    relavent columns in CSV\n",
    "    '''\n",
    "\n",
    "    swift[\"HostName\"]= swift.apply(lambda row: SNHost(row['SNname']), axis=1)\n",
    "    swift[\"SNra\"]= swift.apply(lambda row: SNRa(row['SNname']), axis=1)\n",
    "    swift[\"SNdec\"]= swift.apply(lambda row: SNDec(row['SNname']), axis=1)\n",
    "\n",
    "def GrabSNtypes():\n",
    "    def SNtype(SNname):\n",
    "        '''\n",
    "        Takes Supernovae names from CSV and looks them up in the URL below\n",
    "        Then parses the page for the supernovae type and returns it\n",
    "        '''\n",
    "        \n",
    "        url = \"https://www.wis-tns.org/object/\"+SNname\n",
    "\n",
    "        page = requests.get(url)\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "        try:\n",
    "            sn_type= soup.find_all('div', class_= 'value')\n",
    "            sn_type= sn_type[1].get_text()\n",
    "            if str('---') == sn_type:\n",
    "                sn_type= np.nan\n",
    "            else:\n",
    "                sn_type= sn_type.replace('|'.join(['SN']), '')\n",
    "        except Exception:\n",
    "            sn_type= np.nan\n",
    "        ''' \n",
    "        Also collects any Host names not found in SN_host_ra_dec() function\n",
    "        '''\n",
    "        try:\n",
    "            sn_host= soup.find_all('div', class_= 'field field-hostname')\n",
    "            sn_host= sn_host[0].span.next_sibling.text\n",
    "\n",
    "        except Exception:\n",
    "            sn_host= np.nan\n",
    "\n",
    "\n",
    "        return sn_host, sn_type\n",
    "\n",
    "    def SNtype_empty(SNname):\n",
    "            ''' \n",
    "            Returns empty nan series if condition is met\n",
    "            '''\n",
    "            sn_type, sn_host= np.nan, np.nan\n",
    "            return sn_host, sn_type\n",
    "\n",
    "\n",
    "    swift_temp= pd.DataFrame({'SNname':swift['SNname'], 'HostName':swift['HostName'], 'type':swift['type']})\n",
    "    rep= '|'.join(['SN'])\n",
    "    swift_temp['SNname']= swift_temp['SNname'].str.replace(rep, '')\n",
    "\n",
    "    sntype= pd.Series(swift_temp.apply(lambda row: SNtype(row['SNname']) if pd.notna(row['SNname']) and (pd.isna(row['type']) or pd.isna(row['HostName'])) else SNtype_empty(row['SNname']), axis=1))\n",
    "    sntype= pd.DataFrame(sntype.tolist(), columns=['HostName', 'type'], index=sntype.index)\n",
    "    sntype= sntype.replace({r'^\\s*$'}, np.nan, regex=True)\n",
    "    return sntype\n",
    "\n",
    "\n",
    "def getAVbest(inputcoordinates):\n",
    "    '''\n",
    "    Coordinates are input as a single string. Output is the recommended Av value for MW reddening, error, and reference\n",
    "    '''\n",
    "    \n",
    "    #inputcoordinates = sys.argv[1]\n",
    "    testCoords = SkyCoord(inputcoordinates,frame='fk5')\n",
    "    #print('\\n-----\\nReading input files...')\n",
    "    inFile = 'Brown_Walker_table_1.dat'\n",
    "    inTable = pd.read_csv(inFile,header=None,delimiter=' ')\n",
    "    ra = Angle(inTable.iloc[:,1])\n",
    "    dec = Angle(inTable.iloc[:,2])\n",
    "    sourceCoords = SkyCoord(ra,dec,frame='fk5')\n",
    "    \n",
    "    #print('Calculating separation from table coordinates')\n",
    "    separations = testCoords.separation(sourceCoords).arcminute\n",
    "    # compare to the distances in the table\n",
    "    within = np.less(separations,inTable.iloc[:,3])\n",
    "    \n",
    "    # Are any of the input coordinates within the tabulated distance \n",
    "    # of the coordinates in the table?\n",
    "    correctedAV = np.where(within,inTable.iloc[:,4],None) #get calculated value\n",
    "    fix=any(within)\n",
    "    #print('fix?',fix)\n",
    "    \n",
    "    if fix:\n",
    "        AV = next((item for item in correctedAV if item is not None),None)\n",
    "        correctedAVerr = np.where(within,inTable.iloc[:,5],None) #get calculated val\n",
    "        newAVerr = next((item for item in correctedAVerr if item is not None),None)\n",
    "        AVerr = math.sqrt((int(float(newAVerr)))**2+(int(AV)*0.1)**2)\n",
    "        sources=np.where(within,inTable.iloc[:,6],None)\n",
    "        source = next((item for item in sources if item is not None),None)+\",S_F_2011\"\n",
    "        \n",
    "    if not fix:\n",
    "        AVtable = IrsaDust.get_extinction_table(testCoords,show_progress = False)\n",
    "        AV=AVtable['A_SandF'][2]\n",
    "        AVerr = AV*0.1\n",
    "        source = 'S_F_2011'\n",
    "\n",
    "    #print(AV, AVerr, source)\n",
    "    return (AV, AVerr, source)\n",
    "\n",
    "\n",
    "def AV_best():\n",
    "    def AV_empty(Ra, Dec):\n",
    "        ''' \n",
    "        Returns empty nan values if condition is met\n",
    "        '''\n",
    "        AV, AVerr, AVsour= np.nan, np.nan, np.nan\n",
    "        return AV, AVerr, AVsour\n",
    "    def GrabAVbest(Ra,Dec):\n",
    "        '''\n",
    "        Takes Supernovae Ra,Dec data and puts in in the right format before\n",
    "        runing it through the getAVbest function, if there is an Exception\n",
    "        returns nan values\n",
    "        '''\n",
    "        ra_fix, dec_fix = Ra, Dec\n",
    "        ra_fix= ra_fix.replace(\"'\", \"\")\n",
    "        combined= SkyCoord(ra=ra_fix, dec=dec_fix, unit=(u.hour, u.deg)).to_string('hmsdms')\n",
    "        try:\n",
    "            AV, AVerr, AVsour= getAVbest(combined)\n",
    "        except Exception:\n",
    "            AV, AVerr, AVsour= np.nan, np.nan, np.nan\n",
    "        \n",
    "        return AV, AVerr, AVsour\n",
    "\n",
    "    avdata= pd.Series(swift.apply(lambda row: GrabAVbest(row['SNra'], row['SNdec']) if (pd.isna(row['AV']) and pd.notna(row['SNra'])) else AV_empty(row['SNra'], row['SNdec']), axis= 1))\n",
    "    avdata= pd.DataFrame(avdata.to_list(), columns=['AV', 'AVerr', 'AVsour'], index=avdata.index)\n",
    "    avdata= avdata.replace({r'^\\s*$'}, np.nan, regex=True)\n",
    "\n",
    "    return avdata\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb3382fc-cfd6-4ff0-9a4f-56cdc943f4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AllHostData():\n",
    "    '''\n",
    "    Collects all data on Host names by running appropriate data through related \n",
    "    function or empty function.\n",
    "    '''\n",
    "    def host_coords(HostName):\n",
    "        ra,dec= coord_breakup(get_coords(HostName))\n",
    "        return ra,dec\n",
    "    def host_coords_empty(HostName):\n",
    "        ra,dec= np.nan, np.nan\n",
    "        return ra, dec\n",
    "    \n",
    "    def host_lat_long(HostName):\n",
    "        gal_link=getLink(HostName)\n",
    "        lon,lat= LatLong(gal_link)\n",
    "        return lon, lat\n",
    "    def host_lat_long_empty(HostName):\n",
    "        lon,lat= np.nan, np.nan\n",
    "        return lon, lat\n",
    "    \n",
    "    def redshift(HostName):\n",
    "        gal_link=getLink(HostName)\n",
    "        red= Redshift(gal_link)\n",
    "        return red\n",
    "    def redshift_empty(HostName):\n",
    "        red= np.nan\n",
    "        return red\n",
    "    \n",
    "    def morphology(HostName):\n",
    "        gal_link=getLink(HostName)\n",
    "        morph= Morphology(gal_link)\n",
    "        return morph\n",
    "    def morphology_empty(HostName):\n",
    "        morph= np.nan\n",
    "        return morph\n",
    "    \n",
    "    def velocities(HostName):\n",
    "        gal_link=getLink(HostName)\n",
    "        vels= scrapeValues(gal_link)\n",
    "        return vels\n",
    "    def velocities_empty(HostName):\n",
    "        vels= np.nan, np.nan, np.nan, np.nan\n",
    "        return vels\n",
    "    \n",
    "    '''\n",
    "    All 5 lines uses pandas apply and the lambda function with an if else staments inside. Checks if HostName cell is not empty\n",
    "    and checks specfic cell is empty for all cases. If so runs them through their corresponding functions if not runs them\n",
    "    through their corresponding empty functions\n",
    "    '''\n",
    "\n",
    "    coord= pd.Series(swift.apply(lambda row: host_coords(row['HostName']) if (pd.notna(row['HostName']) and pd.isna(row['HostRa'])) else host_coords_empty(row['HostName']), axis=1))\n",
    "    coord= pd.DataFrame(coord.tolist(), columns=['HostRa','HostDec'], index=coord.index)\n",
    "\n",
    "    lon_lat= pd.Series(swift.apply(lambda row: host_lat_long(row['HostName']) if (pd.notna(row['HostName']) and pd.isna(row['Long'])) else host_lat_long_empty(row['HostName']), axis=1))\n",
    "    lon_lat= pd.DataFrame(lon_lat.tolist(), columns=['Long','Lat'], index=lon_lat.index)\n",
    "    lon_lat= lon_lat.replace({r'^\\s*$'}, np.nan, regex=True)\n",
    "\n",
    "    reds= pd.Series(swift.apply(lambda row: redshift(row['HostName']) if (pd.notna(row['HostName']) and pd.isna(row['Redshift'])) else redshift_empty(row['HostName']), axis=1))\n",
    "    reds= pd.DataFrame(reds.tolist(), columns=['Redshift'], index=reds.index)\n",
    "    reds= reds.replace({r'^\\s*$'}, np.nan, regex=True)\n",
    "\n",
    "    morp= pd.Series(swift.apply(lambda row: morphology(row['HostName']) if (pd.notna(row['HostName']) and pd.isna(row['Morphology'])) else morphology_empty(row['HostName']), axis=1))\n",
    "    morp= pd.DataFrame(morp.tolist(), columns=['Morphology'], index=morp.index)\n",
    "    morp= morp.replace({r'^\\s*$'}, np.nan, regex=True)\n",
    "\n",
    "    hvels= pd.Series(swift.apply(lambda row: velocities(row['HostName']) if (pd.notna(row['HostName']) and pd.isna(row['host_velocity'])) else velocities_empty(row['HostName']), axis=1))\n",
    "    hvels= pd.DataFrame(hvels.tolist(), columns=['host_velocity','host_vel_err', 'host_vel_corr', 'host_vel_corr_err'], index=hvels.index)\n",
    "\n",
    "    all_data= pd.concat([coord, lon_lat, reds, morp, hvels], axis=1)\n",
    "    \n",
    "    return all_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5f26db7-5312-46d9-9aef-6d549a29f6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coord_breakup(coord):\n",
    "    \"\"\"\n",
    "    Breaks up a coordinate into its components\n",
    "    \"\"\"\n",
    "    if pd.isna(coord) == True:\n",
    "        ra = np.nan\n",
    "        dec = np.nan\n",
    "        return ra, dec\n",
    "    else:\n",
    "        ra = Angle(coord.ra.hour,unit = u.hour)\n",
    "        dec = coord.dec\n",
    "        return ra, dec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01a90862-2f01-4472-a2bd-448d54bc1464",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Best_Distances():\n",
    "    def Distances_empty(host_vel, Hubble_dm, Hubble_dm_err, Hubble_dm_ref, SBF_dm, SBF_dm_err, SBF_ref, Cep_dm, Cep_dm_err, Cep_ref, TRGB_dm, TRGB_dm_err, TRGB_dm_ref):\n",
    "        '''\n",
    "        returns nans to series if there is no host_velocity value available\n",
    "        '''\n",
    "        best_dm, best_dm_err, best_dm_meth, best_dm_ref= np.nan, np.nan, np.nan, np.nan\n",
    "        return best_dm, best_dm_err, best_dm_meth, best_dm_ref\n",
    "\n",
    "    def Distances(host_vel, Hubble_dm, Hubble_dm_err, Hubble_dm_ref, SBF_dm, SBF_dm_err, SBF_ref, Cep_dm, Cep_dm_err, Cep_ref, TRGB_dm, TRGB_dm_err, TRGB_dm_ref):\n",
    "        '''\n",
    "        If there is a host_velocity value, checks if there are values for sbf_dist and cep_dist.\n",
    "        If none for both returns dist_mod as Hubble flow distance.\n",
    "        If SBF, returns sbf_dist as SBF.\n",
    "        If Cepheid, returns cep_dist as Cepheid.\n",
    "        '''\n",
    "        try:\n",
    "            if pd.isnull(Cep_dm)==True and pd.isnull(SBF_dm)==True:\n",
    "                best_dm= Hubble_dm\n",
    "                best_dm_err= Hubble_dm_err\n",
    "                best_dm_meth= \"HF\"\n",
    "                best_dm_ref= Hubble_dm_ref\n",
    "            elif pd.isnull(Cep_dm)==True and pd.isnull(SBF_dm)==False:\n",
    "                best_dm= SBF_dm\n",
    "                best_dm_err= SBF_dm_err\n",
    "                best_dm_method= \"SBF\"\n",
    "                best_dm_ref= SBF_dm_ref\n",
    "            else:\n",
    "                best_dm= Cep_dm\n",
    "                best_dm_err= Cep_dm_err\n",
    "                best_dm_meth= \"Cepheid\"\n",
    "                best_dm_ref= Cep_dm_ref\n",
    "        \n",
    "        except Exception:\n",
    "                    best_dm, best_dm_err, best_dm_meth, best_dm_ref= np.nan, np.nan, np.nan, np.nan\n",
    "\n",
    "        return best_dm, best_dm_err, best_dm_meth, best_dm_ref\n",
    "        \n",
    "    best_dist= pd.Series(swift.apply(lambda row: Distances(row['host_velocity'], row['Hubble_dm'], row['Hubble_dm_err'], row['Hubble_dm_ref'], row['SBF_dm'], row['SBF_dm_err'], row['SBF_dm_ref'], row['Cep_dm'], row['Cep_dm_err'], row['Cep_dm_ref'],row['TRGB_dm'], row['TRGB_dm_err'], row['TRGB_dm_ref']) if pd.notna(row['host_velocity']) else Distances_empty(row['host_velocity'], row['Hubble_dm'], row['Hubble_dm_err'], row['Hubble_dm_ref'], row['SBF_dm'], row['SBF_dm_err'], row['SBF_dm_ref'], row['Cep_dm'], row['Cep_dm_err'], row['Cep_dm_ref'],row['TRGB_dm'], row['TRGB_dm_err'], row['TRGB_dm_ref']), axis=1))\n",
    "    best_dist= pd.DataFrame(best_dist.to_list(), columns=['best_dm', 'best_dm_err', 'best_dm_method', 'best_dm_ref'], index= best_dist.index)\n",
    "    best_dist= best_dist.replace({r'^\\s*$'},np.nan, regex=True)\n",
    "    print(best_dist)\n",
    "    return best_dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06c53dbf-ea11-4a41-a6bb-805feb216e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0            NaN\n",
      "1            NaN\n",
      "2            NaN\n",
      "3            NaN\n",
      "4            NaN\n",
      "5            NaN\n",
      "6            NaN\n",
      "7            NaN\n",
      "8            NaN\n",
      "9    33.18480636\n",
      "Name: best_dm, dtype: object\n",
      "0    12\n",
      "1    12\n",
      "2    12\n",
      "3    12\n",
      "4    12\n",
      "5    12\n",
      "6    12\n",
      "7    12\n",
      "8    12\n",
      "9    12\n",
      "Name: best_dm, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "global swift\n",
    "inputcsv='test.csv'\n",
    "swift= pd.read_csv(inputcsv,on_bad_lines='warn',delimiter=',')\n",
    "#print(swift)\n",
    "#print(swift['HostName'])\n",
    "swift= swift.replace({r'anon',r'Anon',r'AnonHost', r'^\\s*$'},np.nan, regex=True)\n",
    "swift= swift.fillna(AllHostData())\n",
    "\n",
    "print(swift['best_dm'])\n",
    "#swift['best_dm']=swift['Cep_dm'] if pd.notna(swift['Cep_dm']) else swift['SBF_dm'] if pd.notna(swift['SBF_dm']) else swift['Hubble_dm'] \n",
    "\n",
    "\n",
    "\n",
    "#df.animal = df.animal + \", \" + df.type + \", \" + \\\n",
    "#    df.age.astype(str) + \" year\" + np.where(df.age > 1, 's', '')\n",
    "\n",
    "\n",
    "#df.best_dm= df.Cep_dm\n",
    "\n",
    "swift['best_dm']=swift['Hubble_dm']\n",
    "#swift.loc[ np.notna(swift['Cep_dm']),'best_dm'] = swift['Cep_dm']\n",
    "\n",
    "swift['best_dm']=swift['Hubble_dm']\n",
    "\n",
    "\n",
    "\n",
    "#df['FirstName']=df['ID'].apply(lambda x: 'Matt' if x==103 else '')\n",
    "\n",
    "\n",
    "#swift_dist= Best_Distances()\n",
    "#print(swift_dist)\n",
    "#swift= swift.drop(swift.columns.intersection(swift_dist.columns), axis=1).join(swift_dist)\n",
    "\n",
    "#swift.loc[pd.notna(swift['Cep_dm']), 'Best_dm'] = swift['Cep_dm']\n",
    "\n",
    "#swift=swift.fillna('')\n",
    "swift.to_csv('New'+inputcsv, index= False)\n",
    "print(swift['best_dm'])\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6adab6df-7eb1-4c89-b7ff-f51655504d7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     True\n",
       "1     True\n",
       "2     True\n",
       "3     True\n",
       "4    False\n",
       "5    False\n",
       "6    False\n",
       "7    False\n",
       "8    False\n",
       "9    False\n",
       "Name: Cep_dm, dtype: bool"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.notna(swift[\"Cep_dm\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c4fb60f-45fe-4eb1-8673-760dbb82be05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    13\n",
       "1    13\n",
       "2    13\n",
       "3    13\n",
       "Name: Cep_dm, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swift.Cep_dm[pd.notna(swift[\"Cep_dm\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc241c3d-d8c4-4895-b227-c16f200bb7d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    12\n",
       "1    12\n",
       "2    12\n",
       "3    12\n",
       "Name: best_dm, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swift.best_dm[pd.notna(swift[\"Cep_dm\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb9c67c5-4785-4348-b843-b08b98c9e84b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    13\n",
       "1    13\n",
       "2    13\n",
       "3    13\n",
       "Name: Cep_dm, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swift.Cep_dm[pd.notna(swift[\"Cep_dm\"])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99d47415-a0f6-4778-abb2-5ffb11a2feda",
   "metadata": {},
   "outputs": [],
   "source": [
    "swift.best_dm=swift.Hubble_dm\n",
    "swift.loc[(pd.notna(swift[\"TRGB_dm\"]),\"best_dm\")]=swift.loc[(pd.notna(swift[\"TRGB_dm\"]),\"TRGB_dm\")]\n",
    "swift.loc[(pd.notna(swift[\"SBF_dm\"]),\"best_dm\")]=swift.loc[(pd.notna(swift[\"SBF_dm\"]),\"SBF_dm\")]\n",
    "\n",
    "swift.loc[(pd.notna(swift[\"Cep_dm\"]),\"best_dm\")]=swift.loc[(pd.notna(swift[\"Cep_dm\"]),\"Cep_dm\")]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62b0d7cb-ad09-4719-b770-9610f5c8ac80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    13\n",
       "1    13\n",
       "2    13\n",
       "3    13\n",
       "4    14\n",
       "5    14\n",
       "6    15\n",
       "7    15\n",
       "8    12\n",
       "9    12\n",
       "Name: best_dm, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swift.best_dm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd588ca-b565-4c90-a783-920051f1385f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
